{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a676de08",
   "metadata": {},
   "source": [
    "---\n",
    "# Deliverable 2 — Feature Engineering & Classical ML\n",
    "**Task:** Feature Engineering + Machine Learning classifiers (LR, SVM, DT, RF, XGBoost)  \n",
    "**Subject Data used:** WESAD — S2.pkl (Chest + Wrist)  \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62256c1c",
   "metadata": {},
   "source": [
    "## 1. Objective (Week-1 Deliverable)\n",
    "\n",
    "Implement Approach-1: Feature engineering + classical ML classifiers.\n",
    "\n",
    "Deliverables:\n",
    "- Feature extraction from multimodal sensors (chest + wrist)\n",
    "- Train classifiers: Logistic Regression, SVM, Decision Tree, Random Forest, XGBoost\n",
    "- Evaluate models (Accuracy, Precision, Recall, F1, Confusion Matrix, ROC-AUC)\n",
    "- Save `features.csv`, `code.ipynb`, and a small report (report.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1c37be",
   "metadata": {},
   "source": [
    "## 2. Dataset Summary (Short Recap)\n",
    "\n",
    "- **Dataset name:** WESAD — Wearable Stress and Affect Detection  \n",
    "- **Source / Link:** UCI ML Repository — https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection  \n",
    "- **Subject file used:** `S2/S2.pkl` (example subject; same code works for others)  \n",
    "- **Sensors used (this deliverable):**\n",
    "  - Chest: ACC_x, ACC_y, ACC_z, ECG, EMG, EDA, Resp, Temp\n",
    "  - Wrist: ACC_x, ACC_y, ACC_z, BVP, EDA, TEMP\n",
    "- **Sampling rates:** chest ≈ 700 Hz; wrist ≈ 32 Hz (documented in dataset)\n",
    "- **Problem type:** Multi-class classification (states 0 Baseline, 1 Stress, 2 Amusement). Other labels (3–7) exist in the raw file and will be ignored for the classification task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a2c22",
   "metadata": {},
   "source": [
    "## 3. Notebook Outline\n",
    "\n",
    "1. Load WESAD S2.pkl and inspect structure  \n",
    "2. Build chest/wrist arrays and timestamps  \n",
    "3. Segment signals into fixed windows (10-second windows by default)  \n",
    "4. Extract features (time-domain, frequency-domain, physiological) from each window for all sensors  \n",
    "5. Label windows via majority vote of chest labels (keep only classes 0,1,2)  \n",
    "6. Build `features.csv` (X) and target vector (y)  \n",
    "7. Train-test split (stratified), scale where needed  \n",
    "8. Train classifiers (LR, SVM, DT, RF, XGBoost)  \n",
    "9. Evaluate metrics, plot confusion matrices, compute ROC-AUC (multiclass OVR)  \n",
    "10. Save results and show feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e5fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Import libraries \n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60e6b1",
   "metadata": {},
   "source": [
    "## 5. Load WESAD S2.pkl and inspect structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0ced7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['signal', 'label', 'subject']\n",
      "Signal groups: ['chest', 'wrist']\n",
      "Chest keys: ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
      "Wrist keys: ['ACC', 'BVP', 'EDA', 'TEMP']\n",
      "Labels shape: (4255300,)\n"
     ]
    }
   ],
   "source": [
    "# 5. Load data\n",
    "data_path = r\"D:\\Semester 7\\ML\\Project\\WESAD DS\\WESAD\\S2\\S2.pkl\" \n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# quick inspection\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "# signals dictionary keys\n",
    "print(\"Signal groups:\", list(data['signal'].keys()))\n",
    "print(\"Chest keys:\", list(data['signal']['chest'].keys()))\n",
    "print(\"Wrist keys:\", list(data['signal']['wrist'].keys()))\n",
    "print(\"Labels shape:\", np.array(data['label']).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aae9b6",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- `data['signal']['chest']` and `data['signal']['wrist']` are dictionaries mapping sensor names to numpy arrays.\n",
    "- `data['label']` contains time-aligned labels (length matches chest signals).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fdbd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract references to chest, wrist, labels\n",
    "chest = data['signal']['chest']\n",
    "wrist = data['signal']['wrist']\n",
    "labels = np.array(data['label'])  # 1D array; length ~ len(chest signals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1aaa3",
   "metadata": {},
   "source": [
    "## 6. Build DataFrames / arrays for sensors (quick consistency checks)\n",
    "- We'll not convert everything to a single massive DataFrame (very large) — instead we'll operate on numpy arrays and create window-level features.\n",
    "- Confirm shapes and sampling rates (we use documented sampling rates below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651e83cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chest. ACC shape: (4255300, 3)\n",
      "chest. ECG shape: (4255300, 1)\n",
      "chest. EMG shape: (4255300, 1)\n",
      "chest. EDA shape: (4255300, 1)\n",
      "chest. Temp shape: (4255300, 1)\n",
      "chest. Resp shape: (4255300, 1)\n",
      "\n",
      "wrist. ACC shape: (194528, 3)\n",
      "wrist. BVP shape: (389056, 1)\n",
      "wrist. EDA shape: (24316, 1)\n",
      "wrist. TEMP shape: (24316, 1)\n"
     ]
    }
   ],
   "source": [
    "# print shapes for chest sensors\n",
    "for k, v in chest.items():\n",
    "    print(\"chest.\", k, \"shape:\", np.array(v).shape)\n",
    "print()\n",
    "for k, v in wrist.items():\n",
    "    print(\"wrist.\", k, \"shape:\", np.array(v).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97741e8",
   "metadata": {},
   "source": [
    "## 7. Windowing strategy\n",
    "- Window duration: 10 seconds (configurable).  \n",
    "- chest_freq = 700 Hz → window_size_chest = 700 * 10 = 7000 samples.  \n",
    "- wrist_freq = 32 Hz → window_size_wrist = 32 * 10 = 320 samples.  \n",
    "- Number of windows used: `min(floor(len(chest_signal)/window_size_chest), floor(len(wrist_signal)/window_size_wrist))` to ensure full data exists for both chest & wrist for each window index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1803bd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size (samples): chest=7000, wrist=320\n",
      "Available windows: chest: 607 wrist: 607 using: 607\n"
     ]
    }
   ],
   "source": [
    "# 7. Window parameters\n",
    "chest_fs = 700\n",
    "wrist_fs = 32\n",
    "window_sec = 10\n",
    "w_chest = int(chest_fs * window_sec)\n",
    "w_wrist = int(wrist_fs * window_sec)\n",
    "\n",
    "# compute number of windows available\n",
    "num_windows_chest = len(chest['ACC']) // w_chest\n",
    "# choose wrist base on 'ACC' or 'BVP' whichever exists\n",
    "num_windows_wrist = len(wrist['ACC']) // w_wrist\n",
    "num_windows = min(num_windows_chest, num_windows_wrist)\n",
    "\n",
    "print(f\"Window size (samples): chest={w_chest}, wrist={w_wrist}\")\n",
    "print(\"Available windows: chest:\", num_windows_chest, \"wrist:\", num_windows_wrist, \"using:\", num_windows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ac2b6",
   "metadata": {},
   "source": [
    "## 8. Helper functions — feature extraction\n",
    "We implement:\n",
    "- time-domain features\n",
    "- frequency-domain features (FFT based)\n",
    "- sensor-specific physiological features:\n",
    "  - ACC: vector magnitude and SMA\n",
    "  - EDA: peak counts, mean, tonic\n",
    "  - ECG: simple R-peak approach for RR intervals → HR and RMSSD (approximate)\n",
    "  - EMG: RMS and zero-crossing rate\n",
    "  - Resp & Temp & BVP: statistical + spectral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c3f92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Feature functions\n",
    "\n",
    "def time_features(x):\n",
    "    \"\"\"Return dict of common time-domain features for 1D numpy array x.\"\"\"\n",
    "    x = np.asarray(x).astype(float)\n",
    "    feats = {}\n",
    "    feats['mean'] = np.mean(x)\n",
    "    feats['median'] = np.median(x)\n",
    "    feats['std'] = np.std(x)\n",
    "    feats['var'] = np.var(x)\n",
    "    feats['min'] = np.min(x)\n",
    "    feats['max'] = np.max(x)\n",
    "    feats['25perc'] = np.percentile(x, 25)\n",
    "    feats['75perc'] = np.percentile(x, 75)\n",
    "    feats['skew'] = skew(x) if x.size > 2 else 0.0\n",
    "    feats['kurtosis'] = kurtosis(x) if x.size > 3 else 0.0\n",
    "    feats['rms'] = np.sqrt(np.mean(x**2))\n",
    "    return feats\n",
    "\n",
    "def freq_features(x, fs):\n",
    "    \"\"\"Return basic frequency-domain features for 1D array x sampled at fs.\"\"\"\n",
    "    x = np.asarray(x).astype(float)\n",
    "    n = len(x)\n",
    "    if n < 2:\n",
    "        return {'dominant_freq':0.0,'spectral_energy':0.0,'power_low':0.0,'power_high':0.0}\n",
    "    X = np.abs(fft(x))\n",
    "    X = X[:n//2]  # positive freqs\n",
    "    freqs = np.fft.fftfreq(n, d=1.0/fs)[:n//2]\n",
    "    # avoid nan errors\n",
    "    if np.all(X == 0):\n",
    "        dominant = 0.0\n",
    "    else:\n",
    "        dominant = float(freqs[np.nanargmax(X)])\n",
    "    spectral_energy = float(np.sum(X**2))\n",
    "    # HRV/resp bands: low (0.04-0.15), high (0.15-0.4) — meaningful for HR/resp\n",
    "    low_mask = (freqs >= 0.04) & (freqs <= 0.15)\n",
    "    high_mask = (freqs >= 0.15) & (freqs <= 0.4)\n",
    "    power_low = float(np.sum(X[low_mask]**2)) if low_mask.any() else 0.0\n",
    "    power_high = float(np.sum(X[high_mask]**2)) if high_mask.any() else 0.0\n",
    "    return {'dominant_freq':dominant,'spectral_energy':spectral_energy,'power_low':power_low,'power_high':power_high}\n",
    "\n",
    "def eda_features(x):\n",
    "    x = np.asarray(x).astype(float).flatten()\n",
    "    feats = {}\n",
    "    # detect peaks (simple) — threshold small positive to ignore tiny noise\n",
    "    try:\n",
    "        peaks, _ = find_peaks(x, height=np.std(x)*0.2 if np.std(x)>0 else 0.01)\n",
    "        feats['eda_num_peaks'] = len(peaks)\n",
    "    except Exception:\n",
    "        feats['eda_num_peaks'] = 0\n",
    "    feats['eda_mean'] = np.mean(x)\n",
    "    feats['eda_tonic'] = np.min(x)  # tonic as minimum in the window\n",
    "    return feats\n",
    "\n",
    "def acc_physio_features(x3):\n",
    "    # x3: Nx3 accelerometer window array\n",
    "    x3 = np.asarray(x3).astype(float)\n",
    "    # vector magnitude\n",
    "    vm = np.sqrt((x3**2).sum(axis=1))\n",
    "    feats = {}\n",
    "    feats['acc_vm_mean'] = np.mean(vm)\n",
    "    feats['acc_vm_std'] = np.std(vm)\n",
    "    feats['acc_sma'] = np.sum(np.abs(vm)) / len(vm) if len(vm)>0 else 0.0\n",
    "    feats['acc_vm_rms'] = np.sqrt(np.mean(vm**2)) if len(vm)>0 else 0.0\n",
    "    return feats\n",
    "\n",
    "def emg_features(x, fs):\n",
    "    x = np.asarray(x).astype(float)\n",
    "    feats = time_features(x)\n",
    "    # zero crossing rate\n",
    "    zc = np.sum(np.abs(np.diff(np.sign(x))))/ (2*len(x)) if len(x)>1 else 0.0\n",
    "    feats['emg_zcr'] = zc\n",
    "    feats['emg_rms'] = np.sqrt(np.mean(x**2)) if len(x)>0 else 0.0\n",
    "    # spectral energy for EMG\n",
    "    ff = freq_features(x, fs)\n",
    "    feats.update({'emg_spec_energy': ff['spectral_energy'], 'emg_dom_freq': ff['dominant_freq']})\n",
    "    return feats\n",
    "\n",
    "def ecg_hrv_features(x, fs):\n",
    "    \"\"\"\n",
    "    A simple R-peak like detection using find_peaks on ECG.\n",
    "    This is approximate — for production use a specialized ECG R-peak detector (e.g., Pan-Tompkins).\n",
    "    Returns heart rate and simple HRV metric (RMSSD).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x).astype(float).flatten()\n",
    "    feats = {}\n",
    "    if len(x) < 10:\n",
    "        feats['ecg_hr_mean'] = 0.0\n",
    "        feats['ecg_rmssd'] = 0.0\n",
    "        return feats\n",
    "    # basic peak detection — require peaks bigger than mean+std\n",
    "    try:\n",
    "        height_thr = np.mean(x) + 0.5*np.std(x)\n",
    "        peaks, _ = find_peaks(x, height=height_thr, distance=int(0.4*fs))  # at least 0.4s between peaks\n",
    "    except Exception:\n",
    "        peaks = np.array([])\n",
    "    # compute RR intervals (seconds)\n",
    "    if len(peaks) >= 2:\n",
    "        rr = np.diff(peaks) / float(fs)  # seconds\n",
    "        hr = 60.0 / np.mean(rr) if np.mean(rr)>0 else 0.0\n",
    "        # RMSSD\n",
    "        diffs = np.diff(rr)\n",
    "        rmssd = np.sqrt(np.mean(diffs**2)) if diffs.size>0 else 0.0\n",
    "    else:\n",
    "        hr = 0.0\n",
    "        rmssd = 0.0\n",
    "    feats['ecg_hr_mean'] = float(hr)\n",
    "    feats['ecg_rmssd'] = float(rmssd)\n",
    "    return feats\n",
    "\n",
    "def simple_spectral_entropy(x, fs):\n",
    "    \"\"\"(Optional) approximate spectral entropy using FFT power distribution.\"\"\"\n",
    "    x = np.asarray(x).astype(float)\n",
    "    n = len(x)\n",
    "    if n < 2:\n",
    "        return 0.0\n",
    "    X = np.abs(fft(x))[:n//2]\n",
    "    P = X**2\n",
    "    if P.sum() == 0:\n",
    "        return 0.0\n",
    "    P_norm = P / P.sum()\n",
    "    # entropy = -sum(P * log(P))\n",
    "    entropy = -np.sum(P_norm * np.log2(P_norm + 1e-12))\n",
    "    return float(entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f038e",
   "metadata": {},
   "source": [
    "## 9. Construct window-level features for *all* selected sensors\n",
    "- For each window index `i` from 0 to `num_windows-1`, extract the chest and wrist segments.\n",
    "- Compute sensor-specific features and combine into a single feature vector per window.\n",
    "- Label each window by majority chest label inside that window.\n",
    "- Keep only windows whose majority label ∈ {0,1,2}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28da268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:222: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "d:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:180: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "d:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:214: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "d:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "d:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m win_feats.update({\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwr_bvp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m freq_features(bvp_wr_seg, wrist_fs).items()})\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# wrist EDA\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m win_feats.update({\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwr_eda_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43meda_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43meda_wr_seg\u001b[49m\u001b[43m)\u001b[49m.items()})\n\u001b[32m     79\u001b[39m win_feats.update({\u001b[33m'\u001b[39m\u001b[33mwr_eda_spec_entropy\u001b[39m\u001b[33m'\u001b[39m: simple_spectral_entropy(eda_wr_seg, wrist_fs)})\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# wrist temp\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36meda_features\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     50\u001b[39m     feats[\u001b[33m'\u001b[39m\u001b[33meda_num_peaks\u001b[39m\u001b[33m'\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     51\u001b[39m feats[\u001b[33m'\u001b[39m\u001b[33meda_mean\u001b[39m\u001b[33m'\u001b[39m] = np.mean(x)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m feats[\u001b[33m'\u001b[39m\u001b[33meda_tonic\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# tonic as minimum in the window\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feats\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3302\u001b[39m, in \u001b[36mmin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3190\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[32m   3191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3192\u001b[39m         where=np._NoValue):\n\u001b[32m   3193\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3194\u001b[39m \u001b[33;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[32m   3195\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3300\u001b[39m \u001b[33;03m    6\u001b[39;00m\n\u001b[32m   3301\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3303\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Semester 7\\ML\\Project\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "# 9. Build features across windows (this may take a few minutes)\n",
    "features = []\n",
    "window_labels = []\n",
    "\n",
    "for i in range(num_windows):\n",
    "    # chest indices (samples)\n",
    "    c_start = i * w_chest\n",
    "    c_end = c_start + w_chest\n",
    "    # wrist indices\n",
    "    w_start = i * w_wrist\n",
    "    w_end = w_start + w_wrist\n",
    "\n",
    "    # chest segments\n",
    "    acc_ch_seg = chest['ACC'][c_start:c_end]         # shape (w_chest, 3)\n",
    "    ecg_ch_seg = chest['ECG'][c_start:c_end].flatten()\n",
    "    emg_ch_seg = chest['EMG'][c_start:c_end].flatten()\n",
    "    eda_ch_seg = chest['EDA'][c_start:c_end].flatten()\n",
    "    resp_ch_seg = chest['Resp'][c_start:c_end].flatten()\n",
    "    temp_ch_seg = chest['Temp'][c_start:c_end].flatten()\n",
    "\n",
    "    # wrist segments (slice to available)\n",
    "    acc_wr_seg = wrist['ACC'][w_start:w_end] if 'ACC' in wrist else np.zeros((w_wrist,3))\n",
    "    bvp_wr_seg = wrist['BVP'][w_start:w_end].flatten() if 'BVP' in wrist else np.zeros(w_wrist)\n",
    "    eda_wr_seg = wrist['EDA'][w_start:w_end].flatten() if 'EDA' in wrist else np.zeros(w_wrist)\n",
    "    temp_wr_seg = wrist['TEMP'][w_start:w_end].flatten() if 'TEMP' in wrist else np.zeros(w_wrist)\n",
    "\n",
    "    # start building per-window features\n",
    "    win_feats = {}\n",
    "\n",
    "    # chest ACC features (vector magnitude + time + freq)\n",
    "    win_feats.update({f\"ch_{k}\": v for k, v in acc_physio_features(acc_ch_seg).items()})\n",
    "    # also time-domain per axis\n",
    "    for axis_idx, axis_name in enumerate(['acc_x','acc_y','acc_z']):\n",
    "        tfeats = time_features(acc_ch_seg[:, axis_idx])\n",
    "        tfeats = {f\"ch_{axis_name}_{k}\": v for k, v in tfeats.items()}\n",
    "        win_feats.update(tfeats)\n",
    "        ffeats = freq_features(acc_ch_seg[:, axis_idx], chest_fs)\n",
    "        ffeats = {f\"ch_{axis_name}_{k}\": v for k, v in ffeats.items()}\n",
    "        win_feats.update(ffeats)\n",
    "\n",
    "    # chest EDA\n",
    "    win_feats.update({f\"ch_{k}\": v for k, v in eda_features(eda_ch_seg).items()})\n",
    "    win_feats['ch_eda_spec_entropy'] = simple_spectral_entropy(eda_ch_seg, chest_fs)\n",
    "\n",
    "    # chest ECG HRV features\n",
    "    win_feats.update({f\"ch_{k}\": v for k, v in ecg_hrv_features(ecg_ch_seg, chest_fs).items()})\n",
    "    # chest ECG spectral/time features for waveform\n",
    "    win_feats.update({f\"ch_ecg_{k}\": v for k, v in time_features(ecg_ch_seg).items()})\n",
    "    win_feats.update({f\"ch_ecg_{k}\": v for k, v in freq_features(ecg_ch_seg, chest_fs).items()})\n",
    "\n",
    "    # chest EMG features\n",
    "    win_feats.update({f\"ch_emg_{k}\": v for k, v in emg_features(emg_ch_seg, chest_fs).items()})\n",
    "\n",
    "    # chest Resp features\n",
    "    win_feats.update({f\"ch_resp_{k}\": v for k, v in time_features(resp_ch_seg).items()})\n",
    "    win_feats.update({'ch_resp_spec_entropy': simple_spectral_entropy(resp_ch_seg, chest_fs)})\n",
    "    win_feats.update({f\"ch_resp_{k}\": v for k, v in freq_features(resp_ch_seg, chest_fs).items()})\n",
    "\n",
    "    # chest Temp features (slow changing)\n",
    "    win_feats.update({f\"ch_temp_{k}\": v for k, v in time_features(temp_ch_seg).items()})\n",
    "\n",
    "    # wrist ACC features\n",
    "    try:\n",
    "        win_feats.update({f\"wr_{k}\": v for k, v in acc_physio_features(acc_wr_seg).items()})\n",
    "    except Exception:\n",
    "        pass\n",
    "    for axis_idx, axis_name in enumerate(['acc_x','acc_y','acc_z']):\n",
    "        tfeats = time_features(acc_wr_seg[:, axis_idx])\n",
    "        win_feats.update({f\"wr_{axis_name}_{k}\": v for k, v in tfeats.items()})\n",
    "        ffeats = freq_features(acc_wr_seg[:, axis_idx], wrist_fs)\n",
    "        win_feats.update({f\"wr_{axis_name}_{k}\": v for k, v in ffeats.items()})\n",
    "\n",
    "    # wrist BVP\n",
    "    win_feats.update({f\"wr_bvp_{k}\": v for k, v in time_features(bvp_wr_seg).items()})\n",
    "    win_feats.update({f\"wr_bvp_{k}\": v for k, v in freq_features(bvp_wr_seg, wrist_fs).items()})\n",
    "\n",
    "    # wrist EDA\n",
    "    win_feats.update({f\"wr_eda_{k}\": v for k, v in eda_features(eda_wr_seg).items()})\n",
    "    win_feats.update({'wr_eda_spec_entropy': simple_spectral_entropy(eda_wr_seg, wrist_fs)})\n",
    "\n",
    "    # wrist temp\n",
    "    win_feats.update({f\"wr_temp_{k}\": v for k, v in time_features(temp_wr_seg).items()})\n",
    "\n",
    "    # label majority vote from chest labels\n",
    "    lab_window = labels[c_start:c_end]\n",
    "    if len(lab_window) == 0:\n",
    "        majority_label = -1\n",
    "    else:\n",
    "        majority_label = int(np.bincount(lab_window).argmax())\n",
    "\n",
    "    features.append(win_feats)\n",
    "    window_labels.append(majority_label)\n",
    "\n",
    "# convert to DataFrame\n",
    "X_all = pd.DataFrame(features)\n",
    "y_all = np.array(window_labels)\n",
    "\n",
    "print(\"Constructed feature matrix shape:\", X_all.shape)\n",
    "print(\"Raw label distribution:\", np.unique(y_all, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae8b93",
   "metadata": {},
   "source": [
    "## 10. Filter windows to include only target classes (0,1,2) and handle missing values\n",
    "- Remove windows whose majority label is not in {0,1,2}\n",
    "- Remove features with all-NaN or constant values\n",
    "- Fill or drop remaining NaNs conservatively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3883984b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 10. Clean features and labels\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m valid_mask = np.isin(\u001b[43my_all\u001b[49m, [\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m])\n\u001b[32m      3\u001b[39m X = X_all[valid_mask].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m y = y_all[valid_mask]\n",
      "\u001b[31mNameError\u001b[39m: name 'y_all' is not defined"
     ]
    }
   ],
   "source": [
    "# 10. Clean features and labels\n",
    "valid_mask = np.isin(y_all, [0,1,2])\n",
    "X = X_all[valid_mask].reset_index(drop=True)\n",
    "y = y_all[valid_mask]\n",
    "\n",
    "print(\"After filtering to classes 0/1/2 -> X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "# drop columns that are all NaN or constant\n",
    "nunique = X.nunique(dropna=True)\n",
    "drop_cols = list(nunique[nunique <= 1].index)\n",
    "X = X.drop(columns=drop_cols)\n",
    "print(\"Dropped constant columns:\", drop_cols)\n",
    "\n",
    "# Fill remaining NaNs with column median (robust)\n",
    "X = X.fillna(X.median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4f58eb",
   "metadata": {},
   "source": [
    "## 11. Save feature matrix (optional but required in submission)\n",
    "- Save `features.csv` for submission/analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df6b95f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m os.makedirs(out_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m features_csv = os.path.join(out_dir, \u001b[33m\"\u001b[39m\u001b[33mfeatures.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mX\u001b[49m.to_csv(features_csv, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: y}).to_csv(os.path.join(out_dir, \u001b[33m\"\u001b[39m\u001b[33mlabels.csv\u001b[39m\u001b[33m\"\u001b[39m), index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaved features to:\u001b[39m\u001b[33m\"\u001b[39m, features_csv)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 11. Save features and labels to CSV\n",
    "out_dir = \"./deliverable2_outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "features_csv = os.path.join(out_dir, \"features.csv\")\n",
    "X.to_csv(features_csv, index=False)\n",
    "pd.DataFrame({'label': y}).to_csv(os.path.join(out_dir, \"labels.csv\"), index=False)\n",
    "print(\"Saved features to:\", features_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfa388d",
   "metadata": {},
   "source": [
    "## 12. Train/Test split + scaling\n",
    "- Use stratified split to preserve class balance\n",
    "- Use StandardScaler for LR and SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ec7cdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 12. Train/test split (stratified)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\u001b[43mX\u001b[49m, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTrain/test sizes:\u001b[39m\u001b[33m\"\u001b[39m, X_train.shape, X_test.shape)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Scaling (fit on train only)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# 12. Train/test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Train/test sizes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# Scaling (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a2433",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bedf096",
   "metadata": {},
   "source": [
    "## 13. Models to train\n",
    "We will train and evaluate:\n",
    "- Logistic Regression (use scaled features)\n",
    "- SVM (scaled)\n",
    "- Decision Tree (unscaled)\n",
    "- Random Forest (unscaled)\n",
    "- XGBoost (unscaled)\n",
    "\n",
    "We will compute accuracy, precision, recall, F1 and multiclass ROC-AUC (one-vs-rest).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f04e7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Define models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial'),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5cb1d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 14. Training and evaluation loop\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m classes = np.unique(\u001b[43my_train\u001b[49m)\n\u001b[32m      5\u001b[39m y_test_bin = label_binarize(y_test, classes=classes)\n\u001b[32m      7\u001b[39m results = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 14. Training and evaluation loop\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "y_test_bin = label_binarize(y_test, classes=classes)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n===== MODEL: {name} =====\")\n",
    "    if name in ['LogisticRegression', 'SVM']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_proba = model.predict_proba(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        # tree-based .predict_proba probably available\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "        except Exception:\n",
    "            y_proba = None\n",
    "\n",
    "    # classification report\n",
    "    print(classification_report(y_test, y_pred, digits=4, zero_division=0))\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # ROC-AUC (multiclass OVR)\n",
    "    try:\n",
    "        if y_proba is not None and y_proba.shape[1] == len(classes):\n",
    "            y_test_binarized = label_binarize(y_test, classes=classes)\n",
    "            roc_auc = roc_auc_score(y_test_binarized, y_proba, multi_class='ovr')\n",
    "        else:\n",
    "            roc_auc = float('nan')\n",
    "    except Exception:\n",
    "        roc_auc = float('nan')\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}  |  ROC-AUC (ovr): {roc_auc:.4f}\")\n",
    "    results[name] = {'accuracy': acc, 'roc_auc': roc_auc, 'model': model}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
